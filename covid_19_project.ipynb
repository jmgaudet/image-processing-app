{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXwRQzNus1w2"
      },
      "source": [
        "# Covid-19 Radiology Segmentation & Classification\n",
        "COMP 478 Project\n",
        "<br>\n",
        "Jeremy Gaudet\n",
        "<br>\n",
        "ID: 40045224\n",
        "<br>\n",
        "April 25, 2021"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "8j-6IQloABrj"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import cv2 as cv\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
        "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from datetime import datetime\n",
        "import io\n",
        "\n",
        "import sys\n",
        "import os\n",
        "from glob import glob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ie3lhqgqPtj0",
        "outputId": "ad4af54c-56ca-4ae7-aa18-635dc5953e1a"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')\n",
        "# sys.path.append('/content/gdrive/My Drive/COMP478 Project/')\n",
        "# %cd /content/gdrive/My Drive/COMP478 Project/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Global variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "Hcu_YANVCvQC"
      },
      "outputs": [],
      "source": [
        "PATH = '/Users/jeremygaudet/Downloads/COVID-19_Radiography_Dataset'\n",
        "BATCH_SIZE = 32\n",
        "IMAGE_SIZE = (256, 256)\n",
        "IMAGE_WIDTH = IMAGE_SIZE[0]\n",
        "IMAGE_HEIGHT = IMAGE_SIZE[1]\n",
        "NUM_CLASSES = 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loading the images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VW0MAjkCCw9A",
        "outputId": "f168a4ef-cea4-49dd-b96b-532f03aef114"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 21165 files belonging to 4 classes.\nUsing 16932 files for training.\n"
          ]
        }
      ],
      "source": [
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    PATH,\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        "    seed=1337,\n",
        "    image_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yBbLLZZOC_SJ",
        "outputId": "185bc915-59e0-4b0b-83f5-36918da0379f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 21165 files belonging to 4 classes.\nUsing 4233 files for validation.\n"
          ]
        }
      ],
      "source": [
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    PATH,\n",
        "    validation_split=0.2,\n",
        "    subset=\"validation\",\n",
        "    seed=1337,\n",
        "    image_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Analysis"
      ]
    },
    {
      "source": [
        "In this dataset, there are the following four classes of chest x-rays"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YK-V8pkgDG8g",
        "outputId": "06456f34-f3a2-45b0-ad12-e85891382cfa",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['COVID', 'Lung Opacity', 'Normal', 'Viral Pneumonia']\n"
          ]
        }
      ],
      "source": [
        "CLASS_NAMES = train_ds.class_names\n",
        "print(CLASS_NAMES, sep='\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get all training and validation labels and put them into separate lists\n",
        "# NOTE This can take a while\n",
        "training_labels = np.concatenate([y for x, y in train_ds], axis=0)\n",
        "validation_labels = np.concatenate([y for x, y in val_ds], axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distribution of training data:\n\n             class  image count\n0            COVID         2907\n1     Lung Opacity         4825\n2           Normal         8137\n3  Viral Pneumonia         1063\n\n\nDistribution of validation data:\n\n             class  image count\n0            COVID          709\n1     Lung Opacity         1187\n2           Normal         2055\n3  Viral Pneumonia          282\n"
          ]
        }
      ],
      "source": [
        "# Use pandas to store the count of each class in the training set\n",
        "unique, counts = np.unique(training_labels, return_counts=True)\n",
        "train_df = pd.DataFrame(dict(zip(CLASS_NAMES, counts)).items(), columns=[\"class\", \"image count\"])\n",
        "# Do the same for validation set\n",
        "unique, counts = np.unique(validation_labels, return_counts=True)\n",
        "val_df = pd.DataFrame(dict(zip(CLASS_NAMES, counts)).items(), columns=[\"class\", \"image count\"])\n",
        "\n",
        "print('Distribution of training data:\\n')\n",
        "print(train_df)\n",
        "print('\\n\\nDistribution of validation data:\\n')\n",
        "print(val_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'class'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-56-22cf0cbfdf71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mdisplay_distribution_donut\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_count_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-56-22cf0cbfdf71>\u001b[0m in \u001b[0;36mdisplay_distribution_donut\u001b[0;34m(data_frame)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubplot_kw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maspect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"equal\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mclass1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_frame\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'class'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_frame\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'total'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'class'"
          ]
        }
      ],
      "source": [
        "def display_distribution_donut(data_frame):\n",
        "    fig, ax = plt.subplots(figsize=(10, 5), subplot_kw=dict(aspect=\"equal\"))\n",
        "\n",
        "    class1 = data_frame['class']\n",
        "    count = data_frame['total']\n",
        "\n",
        "    wedges, texts = ax.pie(\n",
        "        count, \n",
        "        wedgeprops=dict(width=0.5), \n",
        "        startangle=-40, \n",
        "        colors=['lightcoral','lightsalmon', 'cornflowerblue', 'mediumaquamarine'])\n",
        "\n",
        "    bbox_props = dict(boxstyle=\"square,pad=0.3\", fc=\"w\", ec=\"k\", lw=0.72)\n",
        "    kw = dict(arrowprops=dict(arrowstyle=\"-\"),\n",
        "            bbox=bbox_props, zorder=0, va=\"center\")\n",
        "\n",
        "    for i, p in enumerate(wedges):\n",
        "        ang = (p.theta2 - p.theta1)/2. + p.theta1\n",
        "        y = np.sin(np.deg2rad(ang))\n",
        "        x = np.cos(np.deg2rad(ang))\n",
        "        horizontalalignment = {-1: \"right\", 1: \"left\"}[int(np.sign(x))]\n",
        "        connectionstyle = \"angle,angleA=0,angleB={}\".format(ang)\n",
        "        kw[\"arrowprops\"].update({\"connectionstyle\": connectionstyle})\n",
        "        ax.annotate(f'{class1[i]}\\n{count[i]}', xy=(x, y), xytext=(1.35*np.sign(x), 1.4*y),\n",
        "                    horizontalalignment=horizontalalignment, **kw)\n",
        "    plt.show()\n",
        "\n",
        "display_distribution_donut(val_count_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        },
        "id": "eoVa3rF2DLK9",
        "outputId": "40ef6481-ef42-4fa7-f8a2-1dede099a06d"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 12))\n",
        "for images, labels in train_ds.take(1):\n",
        "    for i in range(12):\n",
        "        ax = plt.subplot(3, 4, i + 1)\n",
        "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "        plt.title(CLASS_NAMES[labels[i]])\n",
        "        plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bqtkhQUbDv6i",
        "outputId": "1d88c3b0-1964-4f2d-8751-57a406639717"
      },
      "outputs": [],
      "source": [
        "for image_batch, labels_batch in train_ds:\n",
        "    print(image_batch.shape)\n",
        "    print(labels_batch.shape)\n",
        "    break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Image Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from keras import layers\n",
        "\n",
        "data_augmentation = keras.Sequential(\n",
        "  [\n",
        "    layers.experimental.preprocessing.RandomFlip(\"horizontal\", \n",
        "                                                 input_shape=(IMAGE_HEIGHT, \n",
        "                                                              IMAGE_WIDTH,\n",
        "                                                              3)),\n",
        "    # layers.experimental.preprocessing.RandomRotation(0.01),\n",
        "    # layers.experimental.preprocessing.RandomZoom(0.1),\n",
        "  ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 8))\n",
        "for images, _ in train_ds.take(1):\n",
        "    for i in range(9):\n",
        "        augmented_images = data_augmentation(images)\n",
        "        ax = plt.subplot(3, 3, i + 1)\n",
        "        plt.imshow(augmented_images[0].numpy().astype(\"uint8\"), cmap=\"gray\")\n",
        "        plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yCUB4bgnD-JM"
      },
      "outputs": [],
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BQxTuisBEArZ"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential([ \n",
        "    data_augmentation,\n",
        "    layers.experimental.preprocessing.Rescaling(1./255),\n",
        "    layers.Conv2D(32, 3, activation='relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Conv2D(64, 3, activation='relu'), # was 32\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Conv2D(128, 3, activation='relu'), # 32\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(256, activation='relu'), # 128\n",
        "    layers.Dense(NUM_CLASSES)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E5NoLPwNEE35"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2B3_nzR-EJtN",
        "outputId": "1a86b21f-a581-4cf8-b9ef-a82f5154f4da"
      },
      "outputs": [],
      "source": [
        "hist = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=10\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_hist(hist):\n",
        "    plt.plot(hist.history[\"accuracy\"])\n",
        "    plt.plot(hist.history[\"val_accuracy\"])\n",
        "    plt.title(\"model accuracy\")\n",
        "    plt.ylabel(\"accuracy\")\n",
        "    plt.xlabel(\"epoch\")\n",
        "    plt.legend([\"train\", \"validation\"], loc=\"upper left\")\n",
        "    plt.show()\n",
        "\n",
        "plot_hist(hist)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def validation_data_categories(test_images):\n",
        "    y_pred = model.predict(test_images)\n",
        "    predicted_cat = tf.argmax(y_pred, axis=1)\n",
        "    true_cat = tf.concat([y for x, y in test_images], axis=0)\n",
        "    return true_cat, predicted_cat\n",
        "\n",
        "def plot_confusion_matrix(true_cat, predicted_cat):\n",
        "    cm = confusion_matrix(predicted_cat, true_cat)\n",
        "    display = ConfusionMatrixDisplay(cm).plot()\n",
        "    plt.show()\n",
        "\n",
        "# Show the confusion matrix and the report\n",
        "true_cat, pred_cat = validation_data_categories(val_ds)\n",
        "plot_confusion_matrix(true_cat, pred_cat)\n",
        "print('\\n', classification_report(true_cat, pred_cat, target_names=CLASS_NAMES))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# test_image_path = \"/Users/jeremygaudet/Downloads/istockphoto-173883249-612x612.jpg\"\n",
        "# test_image_path = \"/Users/jeremygaudet/Downloads/c3-1-e1586266398823.jpg.webp\"\n",
        "test_image_path = \"/Users/jeremygaudet/Downloads/normal-lung-xray-15x10-by-Yale-Rosen.jpg\"\n",
        "\n",
        "img = keras.preprocessing.image.load_img(test_image_path, target_size=(IMAGE_WIDTH, IMAGE_HEIGHT, 3))\n",
        "\n",
        "# Plot image\n",
        "plt.figure(figsize=(5, 5))\n",
        "plt.imshow(img)\n",
        "plt.axis(\"off\")\n",
        "\n",
        "# Load a model\n",
        "# model_256 = keras.models.load_model('models/covid_lung_model_256_preprocess_drop.h5')\n",
        "\n",
        "# Preprocess image\n",
        "img_array = keras.preprocessing.image.img_to_array(img)\n",
        "img_array = tf.expand_dims(img_array, 0)  # Create batch axis\n",
        "# Make predictions on images\n",
        "predictions = model.predict(img_array)\n",
        "score = tf.nn.softmax(predictions[0])\n",
        "# Get index for highest confidence class\n",
        "idx = np.argmax(score)\n",
        "\n",
        "print(f'This image is {CLASS_NAMES[idx]} with {score[idx]*100:0.2f}% confidence')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the entire model to a HDF5 file.\n",
        "# !mkdir models/\n",
        "# model.save('models/covid_lung_model_256_preprocess_drop_big.h5')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "covid-19_project.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python386jvsc74a57bd00127df5ff4b2e40ac025c0565be56ba516f34c35b9898f44b93e706d8e48218d",
      "display_name": "Python 3.8.6 64-bit ('tf24': conda)"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    },
    "metadata": {
      "interpreter": {
        "hash": "0127df5ff4b2e40ac025c0565be56ba516f34c35b9898f44b93e706d8e48218d"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}